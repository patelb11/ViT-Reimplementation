# ðŸ“š ViT Reimplementation  

This project is a reimplementation of the Vision Transformer (ViT) based on the seminal paper **"An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"**. The goal of this project was to build the ViT architecture from scratch, including components such as the patch embedding, multi-head self-attention, and positional encoding.

## ðŸ“‹ Project Description  
- The code was developed on **Google Colab** to leverage GPU capabilities.  
- A `requirements.txt` file is included for installing all necessary packages in case you are not using Google Colab.  
- The `ViT.py` file contains the complete source code for the ViT implementation.  

## ðŸš€ Tech Stack  
- **Programming Language**: Python  
- **Framework**: PyTorch  
- **Tools**: Google Colab  
